{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6527fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     base_learner\u001b[38;5;241m.\u001b[39mfit(X_bootstrap, y_bootstrap)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#     Add the trained base learner to the list\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     base_learner\u001b[38;5;241m.\u001b[39mappend(base_learner)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Make predictions with each base learner\u001b[39;00m\n\u001b[0;32m     37\u001b[0m base_prediction\u001b[38;5;241m=\u001b[39m[]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train , X_test , y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a list to store the base learners\n",
    "base_learners =[]\n",
    "\n",
    "# Number of base learners(decision trees)\n",
    "num_base_learners=10\n",
    "\n",
    "# Train the base learners\n",
    "for i in range(num_base_learners):\n",
    "#     Create a bootstrap sample of the training data\n",
    "    bootstrap_indices= np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "    X_bootstrap = X_train[bootstrap_indices]\n",
    "    y_bootstrap = y_train[bootstrap_indices]\n",
    "    \n",
    "    \n",
    "#     create and train a base learner (Random forest)\n",
    "    \n",
    "    base_learner = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    base_learner.fit(X_bootstrap, y_bootstrap)\n",
    "    \n",
    "#     Add the trained base learner to the list\n",
    "    base_learner.append(base_learner)\n",
    "    \n",
    "    \n",
    "# Make predictions with each base learner\n",
    "base_prediction=[]\n",
    "for base_learer in base_learner:\n",
    "    y_pred = base_learner.predict(X_test)\n",
    "    base_predictions.append(y_pred)\n",
    "    \n",
    "    \n",
    "# Combine the predictions using majority voting\n",
    "ensemble_predictions = np.round(np.mean(base_predictions, axis=0))\n",
    "\n",
    "# Calculate the accuracy of the esemble predictions\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(\"Esemble Accuracy:\" , accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3a5a8",
   "metadata": {},
   "source": [
    "# Example - 2(MNIST DATASET(HAND WRITTEN DIGITS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e80596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9723e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jyoti\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# fetch the MNIST dataset\n",
    "mnist= fetch_openml('mnist_784', version=1, cache=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "x_train , x_test , y_train , y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a base classifier(Decision Tree)\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize a bagging classifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the bagging classifier\n",
    "bagging_classifier.fit(x_train , y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = bagging_classifier.predict(x_test)\n",
    "\n",
    "# Calculate the accuracy of the baggibg classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Bagging accuracy:\" , accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2936889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
